{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04bfd9f-75d2-4187-8338-51e4973389b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:59:33.491549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-04 15:59:41.661107: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sathlerar/data/conda/lib:/usr/local/CUDA/11.3.0/bin:/usr/local/CUDA/11.3.0/targets/x86_64-linux/lib:/usr/local/cuDNN/8.2.1/CUDA-11.3/lib64:/usr/bin\n",
      "2023-07-04 15:59:41.661248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sathlerar/data/conda/lib:/usr/local/CUDA/11.3.0/bin:/usr/local/CUDA/11.3.0/targets/x86_64-linux/lib:/usr/local/cuDNN/8.2.1/CUDA-11.3/lib64:/usr/bin\n",
      "2023-07-04 15:59:41.661255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-07-04 15:59:52.414761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-04 15:59:52.415403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sathlerar/data/conda/lib:/usr/local/CUDA/11.3.0/bin:/usr/local/CUDA/11.3.0/targets/x86_64-linux/lib:/usr/local/cuDNN/8.2.1/CUDA-11.3/lib64:/usr/bin\n",
      "2023-07-04 15:59:52.415426: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-04 15:59:52.415457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cn4276): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from utils import get_images_from_directory, get_images_from_directory_keyword\n",
    "from matplotlib import pyplot as plt\n",
    "from models import inceptionV3\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4deb27d7-222e-4a1e-a17c-fe208ab6e20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput directory\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9e128ca88e49deb4ad566877dd3882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/gpfs/gsfs8/users/sathlerar/pecot', filename='', title='', show_hidden=False, select_desc='S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0ad533d85e465487d450e9fbfca29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/gpfs/gsfs8/users/sathlerar/pecot', filename='', title='', show_hidden=False, select_desc='S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOutput directory\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421c3a6fe40e4c4ba89138982488c29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/gpfs/gsfs8/users/sathlerar/pecot', filename='', title='', show_hidden=False, select_desc='S…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a98210f06804d9484bd1933eed5c1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Only apply on masks:', layout=Layout(height='30px', width='150px')), Text(value='N…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10a51fe13e64e9db3264e4e0e0aab4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Number of channels:', layout=Layout(height='30px', width='150px')), IntText(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8f42d9fb8c4762a7d95a0842ad9bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Number of classes:', layout=Layout(height='30px', width='150px')), IntText(value=3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd064ad0d6a445fdb490da4289a2f73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Imaging field in x:', layout=Layout(height='30px', width='150px')), IntText(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c107a213cd01415b808e845dda7f8f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Imaging field in y:', layout=Layout(height='30px', width='150px')), IntText(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d000f14782134e79bed0e648770816fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Batch size:', layout=Layout(height='30px', width='150px')), IntText(value=32)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a7eb2d5647447aba8b0531d09bb9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Normalization:', layout=Layout(height='30px', width='150px')), RadioButtons(option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interface import running_parameters_interface\n",
    "nb_runnings = 1\n",
    "J_ROOT = os.readlink('/proc/%s/cwd' % os.environ['JPY_PARENT_PID'])\n",
    "parameters = running_parameters_interface(nb_runnings, J_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df695252-37ab-4c41-a406-b826af0bb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running(nb_runnings, parameters):\n",
    "    for i in range(nb_runnings):\n",
    "        if parameters[0][i].selected==None:\n",
    "            sys.exit(\"Running #\"+str(i+1)+\": You need to select an input directory for images to be processed\")\n",
    "        if parameters[1][i].selected==None:\n",
    "            sys.exit(\"Running #\"+str(i+1)+\": You need to select a trained model to process your images\")\n",
    "        if parameters[2][i].selected==None:\n",
    "            sys.exit(\"Running #\"+str(i+1)+\": You need to select an output directory for processed images\")\n",
    "\n",
    "        print(f\"n_features: {parameters[5][i].children[1].value}\\n\" \\\n",
    "              + f\"n_channels: {parameters[4][i].children[1].value}\\n\" \\\n",
    "              + f\"dimx: {parameters[6][i].children[1].value}\\n\" \\\n",
    "              + f\"dimy: {parameters[7][i].children[1].value}\\n\" \\\n",
    "              + f\"weights_path: {parameters[1][i].selected}\")\n",
    "        \n",
    "        model = inceptionV3(n_features=parameters[5][i].children[1].value, \n",
    "                            n_channels=parameters[4][i].children[1].value,\n",
    "                            dimx=parameters[6][i].children[1].value, \n",
    "                            dimy=parameters[7][i].children[1].value, \n",
    "                            weights_path=parameters[1][i].selected)\n",
    "        \n",
    "        print(f\"data_location: {parameters[0][i].selected}\\n\" \\\n",
    "              + f\"output_location: {parameters[2][i].selected}\\n\" \\\n",
    "              + f\"bs: {parameters[8][i].children[1].value}\\n\" \\\n",
    "              + f\"mask_names: {parameters[3][i].children[1].value}\\n\" \\\n",
    "              + f\"normalization: {parameters[9][i].children[1].value}\")\n",
    "        \n",
    "        run_models_on_directory(parameters[0][i].selected, parameters[2][i].selected, \n",
    "                                model, bs=parameters[8][i].children[1].value, maxDim=800, \n",
    "                                mask_names=parameters[3][i].children[1].value, \n",
    "                                normalization=parameters[9][i].children[1].value)\n",
    "        del model\n",
    "        return stacked_images, image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c551367c-268c-4d7a-823f-c04acbb49165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_on_directory(data_location, output_location, model, bs=32, maxDim=800, \n",
    "                            mask_names='None', normalization=\"nuclei segmentation\"):\n",
    "\n",
    "    # determine the number of channels and classes as well as the imaging field dimensions\n",
    "    input_shape = model.layers[0].output_shape\n",
    "    n_channels = input_shape[0][1]\n",
    "    imaging_field_x = int((input_shape[0][1]-1)/2)\n",
    "    imaging_field_y = int((input_shape[0][2]-1)/2)\n",
    "    output_shape = model.layers[-1].output_shape\n",
    "    n_classes = output_shape[-1]\n",
    "\n",
    "    # determine the image size\n",
    "    image_size_x, image_size_y, nb_chan = get_image_sizes(data_location)\n",
    "    print(f\"Image x: {image_size_x}\\n\" \\\n",
    "          + f\"Image y: {image_size_y}\\n\" \\\n",
    "          + f\"Image Channels: {nb_chan}\\n\")\n",
    "    \n",
    "    # process images\n",
    "    cpt = 0\n",
    "    model_output = []\n",
    "    processed_image_list = run_model_on_directory_pixByPix(data_location, mask_names, output_location, model, \n",
    "                                                         win_x = imaging_field_x, win_y = imaging_field_y, \n",
    "                                                         bs=bs, maxDim=maxDim, normalization = normalization)\n",
    "\n",
    "    model_output += [np.stack(processed_image_list, axis = 0)]\n",
    "\n",
    "    return model_output, processed_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42cfd6a8-6aa2-43e7-a3f1-3b53e6a3a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_on_directory_pixByPix(data_location, mask_names, output_location, model, \n",
    "                                    win_x = 30, win_y = 30, bs=32, maxDim=800, \n",
    "                                    normalization=\"nuclei segmentation\"):\n",
    "    \n",
    "    n_classes = model.layers[-1].output_shape[-1]\n",
    "    counter = 0\n",
    "\n",
    "    if mask_names == 'None':\n",
    "        image_list, image_names = get_images_from_directory_w_padding(data_location)\n",
    "    else:\n",
    "        image_list, image_names = get_images_from_directory_keyword(data_location, mask_names, True)\n",
    "    processed_image_list = []\n",
    "\n",
    "    if mask_names != \"None\":\n",
    "        mask_list, image_names = get_images_from_directory_keyword(data_location, mask_names)\n",
    "    \n",
    "    for idx, img in enumerate(image_list):\n",
    "        print(f\"Processing image {idx + 1} of {len(image_list)}: {image_names[idx]}\")\n",
    "        if mask_names == \"None\":\n",
    "            processed_image = run_model_pixByPix(img, model, win_x = win_x, win_y = win_y, \n",
    "                                                 bs=bs, maxDim=maxDim, normalization = normalization)\n",
    "        else:\n",
    "            processed_image = run_model_pixByPixOnMasks(img, mask_list[counter], model, win_x = win_x, win_y = win_y, \n",
    "                                                        bs=bs, maxDim=maxDim, normalization = normalization)\n",
    "        processed_image_list += [processed_image]\n",
    "\n",
    "        # Save images\n",
    "        for i in range(n_classes):\n",
    "            cnnout_dir = os.path.join(output_location, image_names[idx])\n",
    "            if not os.path.isdir(cnnout_dir):\n",
    "                os.mkdir(cnnout_dir)\n",
    "            cnnout_name = os.path.join(cnnout_dir, f\"image_c{i}.tif\")\n",
    "            tiff.imwrite(cnnout_name, processed_image[:,:,i])\n",
    "    \n",
    "    return processed_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c42006-d2ea-48e1-8b2d-3db677b72762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_pixByPix(img, model, win_x = 30, win_y = 30, std = False, split = True, process = True, bs=32, \n",
    "                       maxDim=800, normalization = \"nuclei segmentation\"):                           \n",
    "    if normalization == \"nuclei segmentation\":\n",
    "        for j in range(img.shape[-1]):\n",
    "            img[0,:,:,j] = process_image(img[0,:,:,j], win_x, win_y)\n",
    "    else:\n",
    "        for j in range(img.shape[-1]):\n",
    "            img[0,:,:,j] = process_image_onlyLocalAverageSubtraction(img[0,:,:,j], win_x, win_y)\n",
    "        \n",
    "    img = np.pad(img, pad_width = [(0,0), (win_x, win_x), (win_y,win_y), (0,0)], mode = 'reflect')\n",
    "    n_classes = model.layers[-1].output_shape[-1]\n",
    "    image_size_x = img.shape[1]\n",
    "    image_size_y = img.shape[2]\n",
    "    model_output = np.zeros((image_size_x-2*win_x,image_size_y-2*win_y,n_classes), dtype = np.float32)\n",
    "\n",
    "    print(f\"Input image size: {img.shape[1]}x{img.shape[2]}\\n\" \\\n",
    "          + f\"Image size from model: {image_size_x}x{image_size_y}\\n\" \\\n",
    "          + f\"Image size of stitch: {model_output.shape[0]}x{model_output.shape[1]}\")\n",
    "        \n",
    "    x_minIterator, y_minIterator = win_x, win_y\n",
    "    x_maxIterator = min(image_size_x, maxDim) - win_x\n",
    "    y_maxIterator = min(image_size_y, maxDim) - win_y\n",
    "    \n",
    "    while x_minIterator<(image_size_x-win_x) and y_minIterator<(image_size_y-win_y):\n",
    "        test_images = []\n",
    "        for x in range(x_minIterator, x_maxIterator):\n",
    "            for y in range(y_minIterator, y_maxIterator):\n",
    "                test_images.append(img[0,x-win_x:x+win_x+1,y-win_y:y+win_y+1,:])\n",
    "               \n",
    "        test_images = np.asarray(test_images)\n",
    "        test_images = test_images.astype('float32')\n",
    "\n",
    "        predictions = model.predict(test_images, verbose=1, batch_size=bs)\n",
    "\n",
    "        cpt = 0\n",
    "        print(f\"Iterating...\")\n",
    "        for x in range(x_minIterator, x_maxIterator):\n",
    "            for y in range(y_minIterator, y_maxIterator):\n",
    "                model_output[x-win_x,y-win_y,:] = predictions[cpt,:]\n",
    "                cpt += 1\n",
    "\n",
    "        print(f\"Adjusting Iterator...\")\n",
    "        if x_maxIterator < image_size_x-win_x:\n",
    "            x_minIterator = min(x_maxIterator,image_size_x)\n",
    "            if image_size_x-x_minIterator < maxDim:\n",
    "                x_maxIterator = image_size_x-win_x\n",
    "            else:\n",
    "                x_maxIterator = x_minIterator+maxDim-win_x\n",
    "        else:       \n",
    "            x_minIterator = win_x\n",
    "            x_maxIterator = min(image_size_x,maxDim)-win_x\n",
    "            y_minIterator = min(y_maxIterator,image_size_y)\n",
    "            if image_size_y-y_minIterator < maxDim:\n",
    "                y_maxIterator = image_size_y-win_y\n",
    "            else:\n",
    "                y_maxIterator = y_minIterator+maxDim-win_y\n",
    "\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b33f553f-2dba-47fb-b62a-1fed79e8ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 3\n",
      "n_channels: 1\n",
      "dimx: 65\n",
      "dimy: 65\n",
      "weights_path: /gpfs/gsfs8/users/sathlerar/pecot/InceptionV3/models/nucleiSegmentation/2023-07-04_InceptionV3_1_ch_3_cl_65_65_lr_0.01_withDA_10_ep.h5\n",
      "data_location: /gpfs/gsfs8/users/sathlerar/pecot/for_anal/drg_data/\n",
      "output_location: /gpfs/gsfs8/users/sathlerar/pecot/for_anal/23-07-04_32x32_out/\n",
      "bs: 32\n",
      "mask_names: None\n",
      "normalization: nuclei segmentation\n",
      "Image x: 1132\n",
      "Image y: 1132\n",
      "Image Channels: 1\n",
      "\n",
      "Processing image 1 of 39: 230217mtDNAwithTom20-(5)_Young_i3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stack, img_list \u001b[38;5;241m=\u001b[39m \u001b[43mrunning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_runnings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m, in \u001b[0;36mrunning\u001b[0;34m(nb_runnings, parameters)\u001b[0m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m inceptionV3(n_features\u001b[38;5;241m=\u001b[39mparameters[\u001b[38;5;241m5\u001b[39m][i]\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue, \n\u001b[1;32m     17\u001b[0m                     n_channels\u001b[38;5;241m=\u001b[39mparameters[\u001b[38;5;241m4\u001b[39m][i]\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m     18\u001b[0m                     dimx\u001b[38;5;241m=\u001b[39mparameters[\u001b[38;5;241m6\u001b[39m][i]\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue, \n\u001b[1;32m     19\u001b[0m                     dimy\u001b[38;5;241m=\u001b[39mparameters[\u001b[38;5;241m7\u001b[39m][i]\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue, \n\u001b[1;32m     20\u001b[0m                     weights_path\u001b[38;5;241m=\u001b[39mparameters[\u001b[38;5;241m1\u001b[39m][i]\u001b[38;5;241m.\u001b[39mselected)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_location: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameters[\u001b[38;5;241m0\u001b[39m][i]\u001b[38;5;241m.\u001b[39mselected\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     23\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_location: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameters[\u001b[38;5;241m2\u001b[39m][i]\u001b[38;5;241m.\u001b[39mselected\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     24\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameters[\u001b[38;5;241m8\u001b[39m][i]\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     25\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_names: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameters[\u001b[38;5;241m3\u001b[39m][i]\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m     26\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalization: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameters[\u001b[38;5;241m9\u001b[39m][i]\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mrun_models_on_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxDim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmask_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked_images, image_list\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mrun_models_on_directory\u001b[0;34m(data_location, output_location, model, bs, maxDim, mask_names, normalization)\u001b[0m\n\u001b[1;32m     19\u001b[0m cpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m model_output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 21\u001b[0m processed_image_list \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model_on_directory_pixByPix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mwin_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimaging_field_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimaging_field_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxDim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxDim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mstack(processed_image_list, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_output, processed_image_list\n",
      "Cell \u001b[0;32mIn[17], line 20\u001b[0m, in \u001b[0;36mrun_model_on_directory_pixByPix\u001b[0;34m(data_location, mask_names, output_location, model, win_x, win_y, bs, maxDim, normalization)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(image_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_names[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask_names \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 20\u001b[0m     processed_image \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model_pixByPix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwin_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwin_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxDim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxDim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     processed_image \u001b[38;5;241m=\u001b[39m run_model_pixByPixOnMasks(img, mask_list[counter], model, win_x \u001b[38;5;241m=\u001b[39m win_x, win_y \u001b[38;5;241m=\u001b[39m win_y, \n\u001b[1;32m     24\u001b[0m                                                 bs\u001b[38;5;241m=\u001b[39mbs, maxDim\u001b[38;5;241m=\u001b[39mmaxDim, normalization \u001b[38;5;241m=\u001b[39m normalization)\n",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m, in \u001b[0;36mrun_model_pixByPix\u001b[0;34m(img, model, win_x, win_y, std, split, process, bs, maxDim, normalization)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalization \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuclei segmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m----> 5\u001b[0m         img[\u001b[38;5;241m0\u001b[39m,:,:,j] \u001b[38;5;241m=\u001b[39m process_image(\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m, win_x, win_y)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 4 were indexed"
     ]
    }
   ],
   "source": [
    "stack, img_list = running(nb_runnings, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771c7e3-e84b-45ed-967d-e58e33472b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
